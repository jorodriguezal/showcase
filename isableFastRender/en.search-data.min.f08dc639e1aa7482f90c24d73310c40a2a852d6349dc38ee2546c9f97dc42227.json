[{"id":0,"href":"/showcase/docs/secciones/ilusiones-visuales/fen%C3%B3meno-de-masking/","title":"Fenómeno De Masking","section":"Ilusiones Visuales","content":"\rFenómeno de Masking (enmascaramiento)\r#\rEl masking visual es un fenómeno de percepción visual que se produce cuando la visibilidad de una imagen (objetivo) se ve reducida por la presencia de otra imagen (máscara). Implementación de kinegramas y patrones de Moiré como acercamiento al fenómeno visual de \u0026lsquo;masking\u0026rsquo;.\nKinegramas\r#\rUn kinegrama es un efecto de animación creado moviendo una superposición transparente a rayas a través de una imagen entrelazada. La palabra viene de \u0026ldquo;kine\u0026rdquo;, que significa \u0026ldquo;en movimiento\u0026rdquo;, y \u0026ldquo;-gram\u0026rdquo;, que significa \u0026ldquo;dibujo\u0026rdquo;.\nPatrones de Moiré\r#\rEs un patrón de interferencia que se forma cuando se superponen dos rejillas de líneas, ya sean rectas o curvas, con un cierto ángulo​ o cuando tales rejillas tienen tamaños ligeramente diferentes.\n"},{"id":1,"href":"/showcase/docs/secciones/ilusiones-visuales/introducci%C3%B3n/","title":"Introducción","section":"Ilusiones Visuales","content":"\rIntroducción\r#\rEn este primer informe académico se aborda el tema de ilusiones visuales, centrándose en cinco subtemas específicos: Coloración, Bandas de Mach, Enmascaramiento, Coherencia Espacial y Percepción de Profundidad. El objetivo principal de esta serie de ejercicios es explorar el proceso de percepción y representación de imágenes visuales en el cerebro humano y cómo ciertos patrones, colores y formas pueden engañar a nuestro sistema visual, generando ilusiones que no corresponden a la realidad. Este tema de investigación se seleccionó debido a la importancia de la comprensión del funcionamiento de la percepción visual en las aplicaciones informáticas, que pueden tener múltiples usos en diferentes áreas de la ingeniería. Además, las ilusiones visuales han sido objeto de estudio desde hace mucho tiempo, y su análisis puede proporcionar información valiosa acerca del funcionamiento de nuestro sistema perceptual. En este informe se presentará una descripción detallada de los subtemas desarrollados, explicando sus características y los distintos métodos para abordarlos y comprenderlos mejor. Así mismo, se presentarán ejemplos y experimentos para ilustrar cada uno de ellos, realizando distintos análisis con respecto a los resultados obtenidos.\rLa estructura del informe se divide en las secciones de introducción, métodos, resultados, discusión y conclusiones, donde cada sección se enfoca en un aspecto específico del estudio. En la sección de métodos se explicará la metodología utilizada para realizar los ejercicios. En la sección de resultados se presentarán los ejercicios desarrollados en funcionamiento y en la sección de discusión se analizarán e interpretarán los resultados, estableciendo posibles implicaciones y aplicaciones. "},{"id":2,"href":"/showcase/docs/secciones/integrantes/Johan-Steeb-Rodr%C3%ADguez-Alarc%C3%B3n/","title":"Johan Steeb Rodríguez Alarcón","section":"Integrantes","content":"\rJohan Steeb Rodríguez Alarcón\r#\rGitHub: jorodriguezal\n"},{"id":3,"href":"/showcase/docs/secciones/p5/iframe/","title":"Iframe","section":"P5","content":"p5 iframe shortcodes embed p5.js code within an iframe element. There are two p5 iframe shortcodes: p5-iframe and p5-global-iframe.\np5-iframe\r#\r{{\u0026lt; p5-iframe ver=\u0026#34;1.5.0\u0026#34; sketch=\u0026#34;/path/to/sketch.js\u0026#34; lib1=\u0026#34;https://cdntolib1/lib1.js\u0026#34; width=\u0026#34;800\u0026#34; height=\u0026#34;600\u0026#34; \u0026gt;}} All parameters are optional but sketch. Default values are shown in the above snippet but for libs*. Up to lib5 libs may be specified.\nColor relativity\r#\rLook at this brief explanation about what color relativity is.\np5-iframe markdown\r{{\u0026lt; p5-iframe sketch=\u0026#34;/showcase/sketches/monocular_cues/sketch.js\u0026#34; width=\u0026#34;725\u0026#34; height=\u0026#34;425 \u0026gt;}}\rThird party libraries\r#\rExample adapted from p5.EasyCam.\np5-iframe markdown\r{{\u0026lt; p5-iframe sketch=\u0026#34;/showcase/sketches/quick_easycam.js\u0026#34; lib1=\u0026#34;https://cdn.jsdelivr.net/gh/freshfork/p5.EasyCam@1.2.1/p5.easycam.min.js\u0026#34; width=\u0026#34;525\u0026#34; height=\u0026#34;525\u0026#34; \u0026gt;}}\rSound\r#\rExample took from the p5 examples.\np5-iframe markdown\r{{\u0026lt; p5-iframe sketch=\u0026#34;/showcase/sketches/sound.js\u0026#34; width=\u0026#34;225\u0026#34; height=\u0026#34;225\u0026#34; \u0026gt;}}\rp5-global-iframe\r#\r{{\u0026lt; p5-global-iframe id=\u0026#34;sketchid\u0026#34; ver=\u0026#34;1.5.0\u0026#34; lib1=\u0026#34;https://cdntolib1/lib1.js\u0026#34; width=\u0026#34;800\u0026#34; height=\u0026#34;600\u0026#34; \u0026gt;}} // inline sketch code {{\u0026lt; /p5-global-iframe \u0026gt;}} Note that the inline sketch should be coded in p5 global mode syntax.\rAll parameters are optional but id. Default values are shown in the above snippet but for libs*. Up to lib5 libs may be specified.\nBreathing square\r#\rLook at this reference for an explanation and further parameterization of the illusion.\np5-global-iframe markdown\r{{\u0026lt; p5-global-iframe id=\u0026#34;breath\u0026#34; width=\u0026#34;625\u0026#34; height=\u0026#34;625\u0026#34; \u0026gt;}} // Coded as `global mode` of [this](https://github.com/VisualComputing/Cognitive/blob/gh-pages/sketches/rotateSquare.js) let angle = 0; let speed = 0.06; function setup() { createCanvas(600, 600); } function draw() { background(255, 255, 255); rotateSquare(); if (!mouseIsPressed) { strokeWeight(0); stroke(0); fill(255, 140, 0); rect(0, 0, 281, 281); rect(318, 0, 281, 281); rect(0, 318, 281, 281); rect(318, 318, 281, 281); } } function rotateSquare() { push(); angle += speed; strokeWeight(0); stroke(0); fill(0, 0, 255); translate(width / 2, height / 2); rotate(angle); rect(-187.5, -187.5, 375, 375); pop(); } {{\u0026lt; /p5-global-iframe \u0026gt;}}\rp5-widget\r#\rThe p5-widget shortcode embed p5.js code within an p5-widget.\n{{\u0026lt; p5-widget autoplay=true height=\u0026#34;400\u0026#34; width=\u0026#34;400\u0026#34; ver=\u0026#34;1.5.0\u0026#34; \u0026gt;}} // inline sketch code {{\u0026lt; /p5-widget \u0026gt;}} All parameters are optional. Default ver is 1.5.0. For example:\nWidget example\r#\rp5-widget markdown\r{{\u0026lt; p5-widget autoplay=true height=\u0026#34;400\u0026#34; width=\u0026#34;400\u0026#34; ver=\u0026#34;1.5.0\u0026#34; \u0026gt;}} function setup() { createCanvas(300, 300); } function draw() { background(255, 0, 255); } {{\u0026lt; /p5-widget \u0026gt;}}\r"},{"id":4,"href":"/showcase/docs/secciones/ilusiones-visuales/coloraci%C3%B3n/","title":"Coloración","section":"Ilusiones Visuales","content":"\rAntecedentes\r#\rLa percepción del color\r#\rLa percepción del color humana es una de las más complejas de las que se tiene conocimiento. Es un proceso que se lleva a cabo en el cerebro, y que se basa en la estimación de la longitud de onda de la luz que llega a los ojos. La longitud de onda de la luz visible oscila entre 380 y 750 nanómetros (nm). Esta se divide en tres bandas: roja, verde y azul. La luz que se encuentra en el rango de 380 a 450 nm se considera azul, la luz que se encuentra en el rango de 450 a 570 nm se considera verde, y la luz que se encuentra en el rango de 570 a 750 nm se considera roja. En el ojo humano, la luz que llega a la retina se divide en tres tipos de células: conos y bastones. Los conos son responsables de la percepción del color, mientras que los bastones son responsables de la percepción de la luminosidad. Los conos se dividen en tres tipos: conos rojos, verdes y azules. Cada uno de estos conos es sensible a una longitud de onda específica.\rLa información que llega a los conos se combina en el cerebro para generar la percepción del color. La información que llega a los conos rojos se combina con la información que llega a los conos verdes para generar la percepción del color amarillo. La información que llega a los conos verdes se combina con la información que llega a los conos azules para generar la percepción del color cian. Y la información que llega a los conos azules se combina con la información que llega a los conos rojos para generar la percepción del color magenta.\rDaltonismo El daltonismo es una condición que afecta a la percepción del color. Se caracteriza por la incapacidad de distinguir entre ciertos colores. En la mayoría de los casos, las personas con daltonismo no pueden distinguir entre el rojo y el verde. Se pueden distinguir los siguientes tipos de daltonismo:\rProtanopia : dificultad para percibir el color rojo. Deuteranopia : dificultad para percibir el color verde. Tritanopia : dificultad para percibir el color azul. Achromatopsia : incapacidad para percibir el color. Además se tienen las versiones más leves de estos tipos de daltonismo, que son:\nProtanomalia : dificultad leve para percibir el color rojo. Deuteranomalia : dificultad leve para percibir el color verde. Tritanomalia : dificultad leve para percibir el color azul. Achromatomalia : dificultad leve para percibir el color. Ejercicio realizado\r#\rMediante el mapeo de colores, se puede simular el daltonismo. Para ello, se analizan los colores que se encuentran en la imagen, y se reemplazan por los colores que se encuentran en la paleta de colores del daltonismo.\rMétodo utilizado\r#\rMapeo de colores para simular daltonismo En primer lugar, se sabe que, al igual que como se mencionó anteriormente, el color se puede dividir en tres bandas: roja, verde y azul. Este método es utilizado por los computadores para representar los colores, usando formatos como RGB, por lo cual, se facilita el análisis de los colores de la imagen.\rAdemás, se han planteado las matrices de transformación de colores, que permiten transformar los colores al multiplicar el vector de colores por estas. Para poder modificar los colores de la imagen y simular el daltonismo, se utilizan matrices de transformación que ya se han plantado para cada tipo de daltonismo. Estas se pueden encontrar en la siguiente página: https://gist.github.com/Lokno/df7c3bfdc9ad32558bb7 Finalmente, se recorre la imagen pixel por pixel, y se obtiene el color de cada uno de estos. Luego, se transforma el color a la paleta de colores del daltonismo ejegido, y se reemplaza el color original por el nuevo color.\rEvaluación de efectividad de filtros de color de Windows Microsoft Windows, en todas sus versiones, es uno de los sistemas operativos más utilizados en el mundo. En este, se pueden encontrar filtros de color que permiten que las personas con distintos tipos de daltonismo puedan ver mejor las diferencias entre los colores que les causan confusión. Para evaluar la efectividad de estos filtros, se utilizaron imágenes de referencia, a estas se les aplicó el filtro de color de Windows 11 y luego se les realizó la simulación de daltonismo con el método planteado anteriormente a todos los pares de imágenes para poder ver las diferencias entre la percepción de los colores sin el filtro y con el filtro.\rResultados\r#\rMapeo de colores para simular daltonismo\r#\rSe implementó el ejercicio en el lenguaje de programación JavaScript, utilizando la librería p5.js. Se puede ver el resultado a continuación:\nEn este, se tiene una imagen inicial de referencia con la que se pueden ver fácilmente las diferencias entre los tipos de daltonismo. También se cuenta con un desplegable que permite seleccionar el tipo de daltonismo que se desea simular y un botón que permite cargar una imagen distinta.\rLas matrices utilizadas se pueden observar en el siguiente código:\nMatrices de transformación de cada tipo de daltonismo\rvar colorMats = { \u0026#39;Normal\u0026#39;: [ [1,0,0], [0,1,0], [0,0,1] ], \u0026#39;Protanopia\u0026#39;: [ [0.567,0.433,0.000], [0.558,0.442,0.000], [0.000,0.242,0.758] ], \u0026#39;Protanomaly\u0026#39;: [ [0.817,0.183,0.000], [0.333,0.667,0.000], [0.000,0.125,0.875] ], \u0026#39;Deuteranopia\u0026#39;: [ [0.625,0.375,0.000], [0.700,0.300,0.000], [0.000,0.300,0.700] ], \u0026#39;Deuteranomaly\u0026#39;: [ [0.800,0.200,0.000], [0.258,0.742,0.000], [0.000,0.142,0.858] ], \u0026#39;Tritanopia\u0026#39;: [ [0.950,0.050,0.000], [0.000,0.433,0.567], [0.000,0.475,0.525] ], \u0026#39;Tritanomaly\u0026#39;: [ [0.967,0.033,0.000], [0.000,0.733,0.267], [0.000,0.183,0.817] ], \u0026#39;Achromatopsia\u0026#39;: [ [0.299,0.587,0.114], [0.299,0.587,0.114], [0.299,0.587,0.114] ], \u0026#39;Achromatomaly\u0026#39;: [ [0.618,0.320,0.062], [0.163,0.775,0.062], [0.163,0.320,0.516] ] } El código para la transformación de los colores se puede observar en el siguiente código:\nTransformación de los colores\rfunction draw() { ... matrix = colorMats[val]; newImg = createImage(img.width, img.height); newImg.loadPixels(); img.loadPixels(); for (let x = 0; x \u0026lt; img.width; x++) { for (let y = 0; y \u0026lt; img.height; y++) { let index = (x + y * img.width) * 4; let r = img.pixels[index]; let g = img.pixels[index + 1]; let b = img.pixels[index + 2]; let newR = matrix[0][0]*r + matrix[0][1]*g + matrix[0][2]*b; let newG = matrix[1][0]*r + matrix[1][1]*g + matrix[1][2]*b; let newB = matrix[2][0]*r + matrix[2][1]*g + matrix[2][2]*b; newImg.pixels[index] = newR; newImg.pixels[index + 1] = newG; newImg.pixels[index + 2] = newB; newImg.pixels[index + 3] = img.pixels[index + 3]; } }; } Con esto, se pudo simular el daltonismo en distintas imágenes, como se puede observar a continuación:\nComparativa de imágenes\rPaisaje original:\nPaisaje con daltonismo de tipo Protanopia:\nPaisaje con daltonismo de tipo Deuteranopia:\nPaisaje con daltonismo de tipo Tritanopia:\nPaisaje con daltonismo de tipo Achromatopsia:\nSi vemos un caso más extremo, podemos observar que esto puede generar dificultades para la identificación de distintos elementos en la imagen, como se puede observar en el siguiente ejemplo:\rimagen original:\nimagen con daltonismo de tipo Deuteranopia:\nFiltros de color de Windows aplicados a las imágenes\r#\rEstos fueron los resultados de pasar las imágenes confusas por los filtros de color de Windows y luego por el simulador de daltonismo:\nFiltros de color de Windows\rDeuteranopia:\nImagen original:\nImagen con daltonismo de tipo Deuteranopia:\nImagen con daltonismo de tipo Deuteranopia y filtro de color de Windows:\nTritanopia:\nImagen original:\nImagen con daltonismo de tipo Tritanopia:\nImagen con daltonismo de tipo Tritanopia y filtro de color de Windows:\nProtanopia:\nImagen original:\nImagen con daltonismo de tipo Protanopia:\nImagen con daltonismo de tipo Protanopia y filtro de color de Windows:\nConclusiones y trabajo futuro\r#\rMediante este simple ejercicio de simulación se pudieron evidenciar las dificultades que pueden tener las personas con distintos tipos de daltonismo en su día a día. Esto se debe a que, al no poder distinguir ciertos colores, pueden tener dificultades para identificar objetos, personas, etc. Esto puede generar problemas en la vida cotidiana, como por ejemplo, en la conducción de vehículos, en la lectura de señales de tránsito, en la lectura de libros, etc. Por lo que este tipo de ejercicios nos ayudan a comprender mejor la problemática que enfrentan las personas con daltonismo y a generar soluciones que puedan ayudar a mejorar su calidad de vida.\rAdemás, aunque esta herramienta permite la identificación del problema, no es una solución definitiva, ya que, el siquiente paso sería generar una herramienta que permita la transformación de las imágenes de manera automática, para que las personas con daltonismo puedan visualizarlas sin dificultades.\rReferencias\r#\rhttps://es.wikipedia.org/wiki/Daltonismo https://visualcomputing.github.io/docs/visual_illusions/coloring/ https://gist.github.com/Lokno/df7c3bfdc9ad32558bb7 "},{"id":5,"href":"/showcase/docs/secciones/integrantes/Mar%C3%ADa-Alejandra-Jim%C3%A9nez-Herrera/","title":"María Alejandra Jiménez Herrera","section":"Integrantes","content":"\rMaría Alejandra Jiménez Herrera\r#\rGitHub: malejaj\n"},{"id":6,"href":"/showcase/docs/secciones/integrantes/Tania-Valentina-Castillo-Delgado/","title":"Tania Valentina Castillo Delgado","section":"Integrantes","content":"\rTania Valentina Castillo Delgado\r#\rGitHub: tvcastillod\n"},{"id":7,"href":"/showcase/docs/secciones/p5/div/","title":"Div","section":"P5","content":"p5 div shortcodes embed p5.js code within a div element. There are two p5 div shortcodes: p5-div and p5-instance-div.\np5-div\r#\r{{\u0026lt; p5-div ver=\u0026#34;1.5.0\u0026#34; sketch=\u0026#34;/path/to/sketch.js\u0026#34; lib1=\u0026#34;https://cdntolib1/lib1.js\u0026#34; \u0026gt;}} All parameters are optional but sketch. Default values are shown in the above snippet but for libs*. Up to lib5 libs may be specified.\nScintillating grid\r#\rLook at this and also this among many more references there are.\np5-div markdown\r{{\u0026lt; p5-div sketch=\u0026#34;/showcase/sketches/scintillating.js\u0026#34; \u0026gt;}}\rp5-instance-div\r#\r{{\u0026lt; p5-instance-div id=\u0026#34;sketchid\u0026#34; ver=\u0026#34;1.5.0\u0026#34; lib1=\u0026#34;https://cdntolib1/lib1.js\u0026#34; \u0026gt;}} // inline sketch code {{\u0026lt; /p5-instance-div \u0026gt;}} Note that the inline sketch should be coded in p5 instance mode syntax.\rAll parameters are optional but id. Default values are shown in the above snippet but for libs*. Up to lib5 libs may be specified.\nLilac chaser\r#\rLook at this introductory reference.\np5-instance-div markdown\r{{\u0026lt; p5-instance-div id=\u0026#34;lilac-chaser\u0026#34; \u0026gt;}} // Adapted from [this](https://github.com/VisualComputing/Cognitive/blob/gh-pages/sketches/lilacChaser.js) let jump = 0; let count = 0; p5.setup = function() { p5.createCanvas(400, 400); p5.frameRate(7); }; function drawBlurCircles(x, y, r) { p5.push(); p5.noStroke(); var opc = 0.4; var step = 3.0/r; for (var i = r; i \u0026gt; 0; i-=1.5) { if (opc \u0026lt; 5) { opc += step; p5.fill(255, 20, 180, opc); } p5.ellipse(x, y, i, i); } p5.pop(); }; p5.draw = function() { p5.background(200); var numCircles = 12; var stepAngle = 360.0/numCircles; p5.push(); p5.translate(p5.width/2.0, p5.height/2.0); for (var i = 0; i \u0026lt; 360; i = i + stepAngle) { if (i != jump) { p5.push(); p5.rotate(p5.radians(i)); drawBlurCircles(120, 0, 60); p5.pop(); } } if( !p5.mouseIsPressed ) { jump = (jump + stepAngle)%360; } p5.push(); p5.strokeWeight(1.5); p5.line(-7, 0, 7, 0); p5.line(0, -7, 0, 7); p5.pop(); p5.pop(); } {{\u0026lt; /p5-instance-div \u0026gt;}}\rNote that p5 should be the name to be used for the sketch object variable.\rVideo on canvas\r#\rAdapted from here. Don\u0026rsquo;t forget to checkout also the video on dom example.\np5-instance-div markdown\r{{\u0026lt; p5-instance-div id=\u0026#34;video\u0026#34; \u0026gt;}} let fingers; p5.setup = function() { p5.createCanvas(710, 400); // specify multiple formats for different browsers fingers = p5.createVideo([\u0026#39;/showcase/sketches/fingers.mov\u0026#39;, \u0026#39;/showcase/sketches/fingers.webm\u0026#39;]); fingers.hide(); // by default video shows up in separate dom // element. hide it and draw it to the canvas instead }; p5.draw = function() { p5.background(150); p5.image(fingers, 10, 10); // draw the video frame to canvas p5.filter(p5.GRAY); p5.image(fingers, 150, 150); // draw a second copy to canvas }; p5.mousePressed = function() { fingers.loop(); // set the video to loop and start playing } {{\u0026lt; /p5-instance-div \u0026gt;}}\rNote that p5 should be the name to be used for the sketch object variable.\r"},{"id":8,"href":"/showcase/docs/secciones/ilusiones-visuales/percepci%C3%B3n-de-profundidad/","title":"Percepción De Profundidad","section":"Ilusiones Visuales","content":"\rAntecedentes\r#\rPercepción de la profundidad\r#\rLa percepción de profundidad es la habilidad de nuestro sistema visual para percibir la distancia relativa entre los objetos en un espacio tridimensional. Esta habilidad es importante para la percepción espacial y la navegación en el mundo real.\rPistas monoculares Las pistas monoculares son claves visuales que le permiten a nuestro sistema visual percibir la profundidad usando información de un solo ojo (a diferencia de las pistas binoculares, que facilitan la percepción de profundidad). Estas pistas incluyen el tamaño relativo de los objetos, la superposición de objetos, la textura, el gradiente de la perspectiva, entre otros. La combinación de estas pistas permite al sistema visual percibir la profundidad incluso cuando solo se tiene información de un solo ojo. En el contexto de la computación visual, las pistas monoculares se utilizan para crear ilusiones de profundidad en imágenes representadas en un espacio de dos dimensiones.\rEjercicio realizado\r#\rUtilizar la pistas monoculares para representar una escena tridimensional en un espacio de dos dimensiones.\rMétodo utilizado\r#\rPara la realización de este ejercicio se representó una escena simple, que consta de una carretera, una acera y una serie de árboles ubicados a distintas distancias, la cual se puede desplazar tanto horizontal como verticalmente. Además, se pusieron líneas de referencia para poder visualizar la profundidad de la escena.\rCon estos elementos se utilizaron distintas pistas monoculares, las cuales fueron:\nTamaño relativo de los objetos: Se estableció un tamaño relativo entre los objetos, de tal manera que el objeto más cercano se viera más grande y el más lejano más pequeño. Esto se logró con las líneas de referencia, las cuales se colocaron a diferentes distancias de la cámara, y con los árboles, los cuales se colocaron a diferentes distancias de la carretera.\rSuperposición de objetos: Se colocaron los árboles de tal manera que se superpongan entre sí, de tal manera que el árbol más cercano se vea más grande que el más lejano.\rGradiente de la perspectiva: Las líneas de la carretera, ya que son paralelas y se alejan de la cámara, tienden a converger en un punto en el horizonte.\rMovimiento Paralaje: Al moverse la cámara, los árboles se mueven a diferentes velocidades, de tal manera que los árboles más cercanos se mueven más rápido que los más lejanos.\rResultados\r#\rSe implementó el ejercicio en el lenguaje de programación JavaScript, utilizando la librería p5.js. El resultado se puede ver a continuación:\nPara destacar, en el código se plantearon dos variables que permiten modificar el punto de vista de la escena:\nlet finalLine; let XDeviation; Estas corresponden, respectivamente, al punto donde se dibuja el horizonte y la distancia horizontal entre la cámara y la carretera; y pueden ser modificadas en tiempo de ejecución por medio de sliders.\rAdemás, las distintas funciones que dibujan los objetos de la escena, como la carretera, la acera y los árboles, realizan sus cálculos de posición y tamaño en función de estas variables, de tal manera que se pueda modificar el punto de vista de la escena: Función que dibuja cada árbol\rfunction drawTree(img, posX, posY, sizeX, sizeY) { let newImg = img.get(); newImg.resize(sizeX, sizeY); image(newImg, posX, posY); } Función que dibuja las líneas de referencia\rfunction drawBackgroundLines(finalPos) { stroke(\u0026#34;#326133\u0026#34;); let posY = finalPos; let difference = height - finalPos; for (let i = 0; i \u0026lt;= 30; i++) { posY += ((difference / 30) * i) / 15; line(0, posY, width, posY); } return posY; } Función que colorea el cielo\rfunction drawSky(horizon) { noStroke(); fill(\u0026#34;#87ceeb\u0026#34;); beginShape(); vertex(0, 0); vertex(width, 0); vertex(width, horizon); vertex(0, horizon); endShape(); } Función que dibuja la carretera, la acera y los árboles\rfunction drawVanishingRoad(posY) { stroke(\u0026#34;black\u0026#34;); fill(\u0026#34;#5f5f5f\u0026#34;); //Vía beginShape(); vertex(width * (1 / 10) + XDeviation * 10, height); vertex(width / 2 - width / 150, posY); vertex(width / 2 + width / 150, posY); vertex(width * (9 / 10) + XDeviation * 10, height); endShape(); //Andénes fill(\u0026#34;#c4c4c4\u0026#34;); beginShape(); vertex(width * (1 / 10) + XDeviation * 10, height); vertex(width / 2 - width / 150, posY); vertex(0 + XDeviation * 10, height); endShape(); beginShape(); vertex(width * (9 / 10) + XDeviation * 10, height); vertex(width / 2 + width / 150, posY); vertex(width + XDeviation * 10, height); endShape(); fill(\u0026#34;white\u0026#34;); //líneas del centro beginShape(); vertex(width / 2 - 2 * (width * (1 / 40)) + XDeviation * 10, height); vertex(width / 2 - width / 1000, posY); vertex(width / 2 - width * (1 / 70) + XDeviation * 10, height); endShape(); beginShape(); vertex(width / 2 + 2 * (width * (1 / 40)) + XDeviation * 10, height); vertex(width / 2 + width / 1000, posY); vertex(width / 2 + width * (1 / 70) + XDeviation * 10, height); endShape(); //árboles if (treemode) { drawTree(img, width / 2.7 + XDeviation * 1.85, height - posY, 50, 50); drawTree( img, width / 2.7 + XDeviation * 1.85 + width * (4.15 / 24), height - posY, 50, 50 ); drawTree(img, width / 4 + XDeviation * 3.9, height - posY / 1, 100, 100); drawTree( img, width / 4 + XDeviation * 3.9 + width * (4.15 / 12), height - posY / 1, 100, 100 ); drawTree(img, XDeviation * 7.8, height - posY / 1, 200, 200); drawTree( img, XDeviation * 7.8 + width * (4.15 / 6), height - posY / 1, 200, 200 ); } } Conclusiones y trabajo futuro\r#\rEl ejercicio permitió comprender la forma en que el cerebro humano interpreta la información visual cuando no se tiene disponible todo el mecanismo de procesamiento binocular, y cómo esta información es procesada para generar una percepción de profundidad. Además, se pudo apreciar la importancia de las distintas pistas monoculares expuestas y la cercanía de la percepción visual con la realidad física.\rFinalmente, también se hace evidente las facilidades y ventajas de la computación visual para implementar y experimentar con diferentes escenarios de este tipo y así poder comprender mejor estos fenómenos y pensar en sus posibles aplicaciones en los distintos campos de la computación, como lo pueden ser la robótica, la inteligencia artificial o la realidad virtual.\rReferencias\r#\rhttps://visualcomputing.github.io/docs/visual_illusions/depth_perception/ https://es.wikipedia.org/wiki/Percepci%C3%B3n_de_profundidad "},{"id":9,"href":"/showcase/docs/secciones/ilusiones-visuales/","title":"Ilusiones Visuales","section":"Secciones","content":"\rPrimer reporte académico - Ilusiones visuales\r#\rFenómeno De Masking\rFenómeno de Masking (enmascaramiento)\r#\rEl masking visual es un fenómeno de percepción visual que se produce cuando la visibilidad de una imagen (objetivo) se ve reducida por la presencia de otra imagen (máscara). Implementación de kinegramas y patrones de Moiré como acercamiento al fenómeno visual de \u0026lsquo;masking\u0026rsquo;. Kinegramas\r#\rUn kinegrama es un efecto de animación creado moviendo una superposición transparente a rayas a través de una imagen entrelazada.\rIntroducción\rIntroducción\r#\rEn este primer informe académico se aborda el tema de ilusiones visuales, centrándose en cinco subtemas específicos: Coloración, Bandas de Mach, Enmascaramiento, Coherencia Espacial y Percepción de Profundidad. El objetivo principal de esta serie de ejercicios es explorar el proceso de percepción y representación de imágenes visuales en el cerebro humano y cómo ciertos patrones, colores y formas pueden engañar a nuestro sistema visual, generando ilusiones que no corresponden a la realidad.\rColoración\rAntecedentes\r#\rLa percepción del color\r#\rLa percepción del color humana es una de las más complejas de las que se tiene conocimiento. Es un proceso que se lleva a cabo en el cerebro, y que se basa en la estimación de la longitud de onda de la luz que llega a los ojos. La longitud de onda de la luz visible oscila entre 380 y 750 nanómetros (nm).\rPercepción De Profundidad\rAntecedentes\r#\rPercepción de la profundidad\r#\rLa percepción de profundidad es la habilidad de nuestro sistema visual para percibir la distancia relativa entre los objetos en un espacio tridimensional. Esta habilidad es importante para la percepción espacial y la navegación en el mundo real.\rPistas monoculares Las pistas monoculares son claves visuales que le permiten a nuestro sistema visual percibir la profundidad usando información de un solo ojo (a diferencia de las pistas binoculares, que facilitan la percepción de profundidad).\r"},{"id":10,"href":"/showcase/docs/secciones/integrantes/","title":"Integrantes","section":"Secciones","content":"\rIntegrantes del grupo\r#\rJohan Steeb Rodríguez Alarcón\rJohan Steeb Rodríguez Alarcón\r#\rGitHub: jorodriguezal\rMaría Alejandra Jiménez Herrera\rMaría Alejandra Jiménez Herrera\r#\rGitHub: malejaj\rTania Valentina Castillo Delgado\rTania Valentina Castillo Delgado\r#\rGitHub: tvcastillod\r"},{"id":11,"href":"/showcase/docs/secciones/p5/","title":"P5","section":"Secciones","content":"\rp5\r#\rp5 helps add test example p5 sketches into your book. There are two types of p5 shortcodes according to the html element used to embed them.\nTypes\r#\rIframe\rp5 iframe shortcodes embed p5.js code within an iframe element. There are two p5 iframe shortcodes: p5-iframe and p5-global-iframe. p5-iframe\r#\r{{\u0026lt; p5-iframe ver=\u0026#34;1.5.0\u0026#34; sketch=\u0026#34;/path/to/sketch.js\u0026#34; lib1=\u0026#34;https://cdntolib1/lib1.js\u0026#34; width=\u0026#34;800\u0026#34; height=\u0026#34;600\u0026#34; \u0026gt;}} All parameters are optional but sketch. Default values are shown in the above snippet but for libs*. Up to lib5 libs may be specified. Color relativity\r#\rLook at this brief explanation about what color relativity is. p5-iframe markdown\r{{\u0026lt; p5-iframe sketch=\u0026#34;/showcase/sketches/monocular_cues/sketch.\rDiv\rp5 div shortcodes embed p5.js code within a div element. There are two p5 div shortcodes: p5-div and p5-instance-div. p5-div\r#\r{{\u0026lt; p5-div ver=\u0026#34;1.5.0\u0026#34; sketch=\u0026#34;/path/to/sketch.js\u0026#34; lib1=\u0026#34;https://cdntolib1/lib1.js\u0026#34; \u0026gt;}} All parameters are optional but sketch. Default values are shown in the above snippet but for libs*. Up to lib5 libs may be specified. Scintillating grid\r#\rLook at this and also this among many more references there are. p5-div markdown\r{{\u0026lt; p5-div sketch=\u0026#34;/showcase/sketches/scintillating.\r"},{"id":12,"href":"/showcase/menu/","title":"Index","section":"Introduction","content":" Computación Visual Integrantes "}]